{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3146e0c0-233a-4ef6-8427-7f1e8a5f86f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/myenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-19 11:02:22.655357: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"max_split_size_mb:128\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, Trainer, TrainingArguments\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from datasets import Dataset, ClassLabel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2233ed00-2119-491c-8be5-fde386d5ae10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Training_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e22b090-3944-4d8e-a062-540030b6a7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>EmailType</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi *******, Your payment to Uber India was App...</td>\n",
       "      <td>category_3</td>\n",
       "      <td>email_type_93</td>\n",
       "      <td>hi payment uber india approved paid amount ube...</td>\n",
       "      <td>['hi', 'payment', 'uber', 'india', 'approved',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your Zomato Online Ordering receipt Refund Pro...</td>\n",
       "      <td>category_3</td>\n",
       "      <td>email_type_84</td>\n",
       "      <td>zomato online ordering receipt refund processe...</td>\n",
       "      <td>['zomato', 'online', 'ordering', 'receipt', 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electricity Bill Payment Successful ‚Çπ 979 Fo...</td>\n",
       "      <td>category_3</td>\n",
       "      <td>email_type_3</td>\n",
       "      <td>electricity bill payment successful ‚çπ 979 ce...</td>\n",
       "      <td>['electricity', 'bill', 'payment', 'successful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payment requested by FINCFRIENDS PVT. LTD. Rec...</td>\n",
       "      <td>category_3</td>\n",
       "      <td>email_type_92</td>\n",
       "      <td>payment requested fincfriends pvt ltd receipt ...</td>\n",
       "      <td>['payment', 'requested', 'fincfriends', 'pvt',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greetings from Swiggy Your order was delivered...</td>\n",
       "      <td>category_3</td>\n",
       "      <td>email_type_86</td>\n",
       "      <td>greeting swiggy order delivered 29 minute rate...</td>\n",
       "      <td>['greeting', 'swiggy', 'order', 'delivered', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Category  \\\n",
       "0  Hi *******, Your payment to Uber India was App...  category_3   \n",
       "1  Your Zomato Online Ordering receipt Refund Pro...  category_3   \n",
       "2  Electricity Bill Payment Successful ‚Çπ 979 Fo...  category_3   \n",
       "3  Payment requested by FINCFRIENDS PVT. LTD. Rec...  category_3   \n",
       "4  Greetings from Swiggy Your order was delivered...  category_3   \n",
       "\n",
       "       EmailType                                         clean_text  \\\n",
       "0  email_type_93  hi payment uber india approved paid amount ube...   \n",
       "1  email_type_84  zomato online ordering receipt refund processe...   \n",
       "2   email_type_3  electricity bill payment successful ‚çπ 979 ce...   \n",
       "3  email_type_92  payment requested fincfriends pvt ltd receipt ...   \n",
       "4  email_type_86  greeting swiggy order delivered 29 minute rate...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['hi', 'payment', 'uber', 'india', 'approved',...  \n",
       "1  ['zomato', 'online', 'ordering', 'receipt', 'r...  \n",
       "2  ['electricity', 'bill', 'payment', 'successful...  \n",
       "3  ['payment', 'requested', 'fincfriends', 'pvt',...  \n",
       "4  ['greeting', 'swiggy', 'order', 'delivered', '...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09c8f7a8-2316-43a7-9f7a-414572010e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert categorical labels to numerical labels\n",
    "category_labels = ClassLabel(names=list(df['Category'].unique()))\n",
    "type_labels = ClassLabel(names=list(df['EmailType'].unique()))\n",
    "\n",
    "df['Category'] = df['Category'].map(lambda x: category_labels.str2int(x))\n",
    "df['EmailType'] = df['EmailType'].map(lambda x: type_labels.str2int(x))\n",
    "\n",
    "# # Split the data into train and test sets\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Dataset objects\n",
    "train_dataset = Dataset.from_pandas(df)\n",
    "# test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d928343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'category_3', 1: 'category_1', 2: 'category_2'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c7c06fd-a0d1-4622-8bf9-6ec3d45524b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['clean_text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "# test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns(['Text', 'clean_text', 'tokens'])\n",
    "# test_dataset = test_dataset.remove_columns(['Text', 'clean_text', 'tokens'])\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'Category', 'EmailType'])\n",
    "# test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'Category', 'EmailType'])\n",
    "\n",
    "# # Move tensors to the MPS device\n",
    "# train_dataset = train_dataset.with_transform(lambda examples: {k: v.to(device) for k, v in examples.items()})\n",
    "# test_dataset = test_dataset.with_transform(lambda examples: {k: v.to(device) for k, v in examples.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d0dd89-d848-49a0-a288-6a61f398558f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "category_class_weights=compute_class_weight(class_weight = 'balanced',classes = np.unique(train_dataset['Category']),y = list(train_dataset['Category'].numpy()))\n",
    "category_class_weights=torch.tensor(category_class_weights,dtype=torch.float)\n",
    "\n",
    "emailtype_class_weights=compute_class_weight(class_weight = 'balanced',classes=np.unique(train_dataset['EmailType']),y=list(train_dataset['EmailType'].numpy()) )\n",
    "emailtype_class_weights=torch.tensor(emailtype_class_weights,dtype=torch.float)\n",
    "\n",
    "# Convert class weights to dictionary format\n",
    "# category_class_weights_dict = dict(enumerate(category_class_weights))\n",
    "# emailtype_class_weights_dict = dict(enumerate(emailtype_class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91d29e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class MultiTaskBERT(BertPreTrainedModel):\n",
    "    def __init__(self, config, Category, EmailType):\n",
    "        super().__init__(config)\n",
    "        self.Category = Category\n",
    "        self.EmailType = EmailType\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier_category = nn.Linear(config.hidden_size, Category)\n",
    "        self.classifier_type = nn.Linear(config.hidden_size, EmailType)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, Category=None, EmailType=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        logits_category = self.classifier_category(pooled_output)\n",
    "        logits_type = self.classifier_type(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if Category is not None and EmailType is not None:\n",
    "            # add class weights here\n",
    "\n",
    "            loss_fct_category = nn.CrossEntropyLoss()\n",
    "            loss_fct_type = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # loss_fct = nn.CrossEntropyLoss()\n",
    "            loss_category = loss_fct_category(logits_category, Category)\n",
    "            loss_type = loss_fct_type(logits_type, EmailType)\n",
    "            loss = loss_category + loss_type\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=(logits_category, logits_type),\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eed5afc0-cd4e-42bc-ba36-af04d8fa9961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(logits_category, logits_type, labels_category, labels_type):\n",
    "    pred_category = logits_category.argmax(dim=1).cpu()\n",
    "    pred_type = logits_type.argmax(dim=1).cpu()\n",
    "    labels_category = labels_category.cpu()\n",
    "    labels_type = labels_type.cpu()\n",
    "    category_accuracy = accuracy_score(labels_category, pred_category)\n",
    "    type_accuracy = accuracy_score(labels_type, pred_type)\n",
    "    category_precision = precision_score(labels_category, pred_category, average='weighted')\n",
    "    type_precision = precision_score(labels_type, pred_type, average='weighted')\n",
    "    category_f1 = f1_score(labels_category, pred_category, average='weighted')\n",
    "    type_f1 = f1_score(labels_type, pred_type, average='weighted')\n",
    "    category_recall = recall_score(labels_category, pred_category, average='weighted')\n",
    "    type_recall = recall_score(labels_type, pred_type, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'category_accuracy': category_accuracy,\n",
    "        'emailtype_accuracy': type_accuracy,\n",
    "        'category_f1': category_f1,\n",
    "        'emailtype_f1': type_f1,\n",
    "        'category_precision': category_precision,\n",
    "        'emailtype_precision': type_precision,\n",
    "        'category_recall': category_recall,\n",
    "        'emailtype_recall': type_recall,\n",
    "\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d24e8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_labels_category = len(category_labels.names)\n",
    "num_labels_type = len(type_labels.names)\n",
    "\n",
    "def evaluate_model(model, eval_fold_dataset, device):\n",
    "    total_eval_loss = 0\n",
    "    all_logits_category = []\n",
    "    all_logits_type = []\n",
    "    all_labels_category = []\n",
    "    all_labels_type = []\n",
    "    for batch in tqdm(DataLoader(eval_fold_dataset, batch_size=16), desc=f\"Evaluating Fold {fold + 1}/{num_folds} Epoch {epoch + 1}/{num_train_epochs}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()\n",
    "            logits_category, logits_type = outputs.logits\n",
    "            all_logits_category.append(logits_category)\n",
    "            all_logits_type.append(logits_type)\n",
    "            all_labels_category.append(batch['Category'])\n",
    "            all_labels_type.append(batch['EmailType'])\n",
    "\n",
    "    avg_eval_loss = total_eval_loss / len(eval_fold_dataset)\n",
    "    all_logits_category = torch.cat(all_logits_category, dim=0)\n",
    "    all_logits_type = torch.cat(all_logits_type, dim=0)\n",
    "    all_labels_category = torch.cat(all_labels_category, dim=0)\n",
    "    all_labels_type = torch.cat(all_labels_type, dim=0)\n",
    "\n",
    "    metrics = compute_metrics(all_logits_category, all_logits_type, all_labels_category, all_labels_type)\n",
    "    return metrics\n",
    "\n",
    "def update_metrics(metrics, category_metrics, emailtype_metrics):\n",
    "    category_metrics[\"accuracy\"].append(metrics[\"category_accuracy\"])\n",
    "    category_metrics[\"precision\"].append(metrics[\"category_precision\"])\n",
    "    category_metrics[\"recall\"].append(metrics[\"category_recall\"])\n",
    "    category_metrics[\"f1\"].append(metrics[\"category_f1\"])\n",
    "    \n",
    "    emailtype_metrics[\"accuracy\"].append(metrics[\"emailtype_accuracy\"])\n",
    "    emailtype_metrics[\"precision\"].append(metrics[\"emailtype_precision\"])\n",
    "    emailtype_metrics[\"recall\"].append(metrics[\"emailtype_recall\"])\n",
    "    emailtype_metrics[\"f1\"].append(metrics[\"emailtype_f1\"])\n",
    "    return category_metrics, emailtype_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813e071-f170-4ab9-ad6e-58e00ab70a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "category_metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "emailtype_metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "train_category_metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "train_emailtype_metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": []\n",
    "}\n",
    "# Define lists to store evaluation metrics for each fold\n",
    "category_accuracy_list = []\n",
    "type_accuracy_list = []\n",
    "category_f1_list = []\n",
    "type_f1_list = []\n",
    "category_precision_list = []\n",
    "type_precision_list = []\n",
    "num_train_epochs = 3\n",
    "for fold, (train_index, eval_index) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Split the dataset into training and evaluation sets for this fold\n",
    "    train_fold_dataset = train_dataset.select(train_index)\n",
    "    eval_fold_dataset = train_dataset.select(eval_index)\n",
    "\n",
    "    # Initialize model for this fold\n",
    "    model = MultiTaskBERT.from_pretrained('bert-base-uncased', Category=num_labels_category, EmailType=num_labels_type)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define optimizer for this fold\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    # Training loop for this fold\n",
    "    for epoch in range(num_train_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in tqdm(DataLoader(train_fold_dataset, batch_size=8, shuffle=True), desc=f\"Training Fold {fold + 1}/{num_folds} Epoch {epoch + 1}/{num_train_epochs}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_fold_dataset)\n",
    "\n",
    "        # Evaluation loop for this fold\n",
    "        model.eval()\n",
    "    metrics = evaluate_model(model, eval_fold_dataset, device)\n",
    "    category_metrics, emailtype_metrics = update_metrics(metrics, category_metrics, emailtype_metrics)\n",
    "    train_metrics = evaluate_model(model, train_fold_dataset, device)\n",
    "    train_category_metrics, train_emailtype_metrics = update_metrics(train_metrics, train_category_metrics, train_emailtype_metrics)\n",
    "    print(f\"Fold {fold + 1}, Category Train Accuracy: {train_metrics['category_accuracy']:.2f}%, Precision: {train_metrics['category_precision']:.2f}, Recall: {train_metrics['category_recall']:.2f}, F1-Score: {train_metrics['category_f1']:.2f}\")\n",
    "    print(f\"Fold {fold + 1}, EmailType Train Accuracy: {train_metrics['emailtype_accuracy']:.2f}%, Precision: {train_metrics['emailtype_precision']:.2f}, Recall: {train_metrics['emailtype_recall']:.2f}, F1-Score: {train_metrics['emailtype_f1']:.2f}\")\n",
    "    print(f\"Fold {fold + 1}, Category Accuracy: {metrics['category_accuracy']:.2f}%, Precision: {metrics['category_precision']:.2f}, Recall: {metrics['category_recall']:.2f}, F1-Score: {metrics['category_f1']:.2f}\")\n",
    "    print(f\"Fold {fold + 1}, EmailType Accuracy: {metrics['emailtype_accuracy']:.2f}%, Precision: {metrics['emailtype_precision']:.2f}, Recall: {metrics['emailtype_recall']:.2f}, F1-Score: {metrics['emailtype_f1']:.2f}\")\n",
    "    torch.save(model.state_dict(), f\"models/bert_preprocessed_{epoch + 1}.bin\")\n",
    "print(f\"Average Category Accuracy: {np.mean(category_metrics['accuracy']):.2f}%\")\n",
    "print(f\"Average Category Precision: {np.mean(category_metrics['precision']):.2f}\")\n",
    "print(f\"Average Category Recall: {np.mean(category_metrics['recall']):.2f}\")\n",
    "print(f\"Average Category F1-Score: {np.mean(category_metrics['f1']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "995a33ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/3: 100%|██████████| 3513/3513 [46:18<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Average Training Loss: 0.7380412492743083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 1/3: 100%|██████████| 440/440 [04:01<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Average Evaluation Loss: 0.34802815979769963\n",
      "Category Accuracy: 0.9914602903501281, Type Accuracy: 0.9329632792485055\n",
      "Category F1 Score: 0.9917304538108238, Type F1 Score: 0.9229827690683152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/3: 100%|██████████| 3513/3513 [46:17<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Average Training Loss: 0.2581941508437506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 2/3: 100%|██████████| 440/440 [04:01<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Average Evaluation Loss: 0.261272983845662\n",
      "Category Accuracy: 0.9928835752917734, Type Accuracy: 0.9434955878166809\n",
      "Category F1 Score: 0.99276757520957, Type F1 Score: 0.9365035182367243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/3: 100%|██████████| 3513/3513 [46:15<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Average Training Loss: 0.16841492507801067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 3/3: 100%|██████████| 440/440 [04:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Average Evaluation Loss: 0.2273039766238071\n",
      "Category Accuracy: 0.9921719328209507, Type Accuracy: 0.9560204953031597\n",
      "Category F1 Score: 0.9920422716776524, Type F1 Score: 0.9523872022466164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./multi-task-bert/tokenizer_config.json',\n",
       " './multi-task-bert/special_tokens_map.json',\n",
       " './multi-task-bert/vocab.txt',\n",
       " './multi-task-bert/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "eval_dataloader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Function to compute accuracy\n",
    "def compute_accuracy(predictions, labels):\n",
    "    preds = predictions.argmax(dim=1)\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / labels.size(0)\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(logits_category, logits_type, labels_category, labels_type):\n",
    "    pred_category = logits_category.argmax(dim=1)\n",
    "    pred_type = logits_type.argmax(dim=1)\n",
    "\n",
    "    category_accuracy = accuracy_score(labels_category.cpu().numpy(), pred_category.cpu().numpy())\n",
    "    type_accuracy = accuracy_score(labels_type.cpu().numpy(), pred_type.cpu().numpy())\n",
    "\n",
    "    category_f1 = f1_score(labels_category.cpu().numpy(), pred_category.cpu().numpy(), average='weighted')\n",
    "    type_f1 = f1_score(labels_type.cpu().numpy(), pred_type.cpu().numpy(), average='weighted')\n",
    "\n",
    "    return {\n",
    "        'category_accuracy': category_accuracy,\n",
    "        'type_accuracy': type_accuracy,\n",
    "        'category_f1': category_f1,\n",
    "        'type_f1': type_f1,\n",
    "    }\n",
    "\n",
    "num_train_epochs = 3\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_train_epochs}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_train_epochs} - Average Training Loss: {avg_train_loss}\")\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    all_logits_category = []\n",
    "    all_logits_type = []\n",
    "    all_labels_category = []\n",
    "    all_labels_type = []\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=f\"Evaluating Epoch {epoch + 1}/{num_train_epochs}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()\n",
    "            logits_category, logits_type = outputs.logits\n",
    "            all_logits_category.append(logits_category)\n",
    "            all_logits_type.append(logits_type)\n",
    "            all_labels_category.append(batch['Category'])\n",
    "            all_labels_type.append(batch['EmailType'])\n",
    "\n",
    "    avg_eval_loss = total_eval_loss / len(eval_dataloader)\n",
    "    all_logits_category = torch.cat(all_logits_category, dim=0)\n",
    "    all_logits_type = torch.cat(all_logits_type, dim=0)\n",
    "    all_labels_category = torch.cat(all_labels_category, dim=0)\n",
    "    all_labels_type = torch.cat(all_labels_type, dim=0)\n",
    "\n",
    "    metrics = compute_metrics(all_logits_category, all_logits_type, all_labels_category, all_labels_type)\n",
    "    print(f\"Epoch {epoch + 1}/{num_train_epochs} - Average Evaluation Loss: {avg_eval_loss}\")\n",
    "    print(f\"Category Accuracy: {metrics['category_accuracy']}, Type Accuracy: {metrics['type_accuracy']}\")\n",
    "    print(f\"Category F1 Score: {metrics['category_f1']}, Type F1 Score: {metrics['type_f1']}\")\n",
    "    torch.save(model.state_dict(), f\"models/bert_assertion_{epoch + 1}.bin\")\n",
    "# Save the model and tokenizer after training\n",
    "model.save_pretrained('./multi-task-bert')\n",
    "tokenizer.save_pretrained('./multi-task-bert')\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "myenv",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
